{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('python-torch': venv)",
   "metadata": {
    "interpreter": {
     "hash": "fbaf0556274e5564072db3c2590affa55a59ae83f8c6a4767be9e51c7962c74b"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import json\n",
    "import os.path\n",
    "\n",
    "from gat_vqa.config.gqa import GQASplit, GQAVersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files Loading\n",
    "def load_and_apply_to_file(name, apply):\n",
    "    \"\"\"Load a file.\"\"\"\n",
    "    print(name)\n",
    "    # load standard json file\n",
    "    if os.path.isfile(name):\n",
    "        with open(name) as file:\n",
    "            apply(json.load(file))\n",
    "    # load file chunks if too big\n",
    "    elif os.path.isdir(os.path.dirname(name)):\n",
    "        dir_, ext = os.path.splitext(os.path.basename(name))\n",
    "        chunks = glob.glob(\n",
    "            os.path.join(\n",
    "                os.path.dirname(name), \"{dir}/{dir}_*{ext}\".format(dir=dir_, ext=ext)\n",
    "            )\n",
    "        )\n",
    "        print(chunks)\n",
    "        for chunk in chunks:\n",
    "            with open(chunk) as file:\n",
    "                apply(json.load(file))\n",
    "    else:\n",
    "        raise Exception(\"Can't find {}\".format(name))\n",
    "\n",
    "class ImageIDExtractor:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.ids = []\n",
    "\n",
    "    def __call__(self, questions):\n",
    "        new_ids = list(set([q_data['imageId'] for q_data in questions.values()]))\n",
    "        self.ids += new_ids\n",
    "        self.ids = list(set(self.ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data/gqa/questions/train_all_questions.json\n",
      "['data/gqa/questions/train_all_questions/train_all_questions_0.json', 'data/gqa/questions/train_all_questions/train_all_questions_1.json', 'data/gqa/questions/train_all_questions/train_all_questions_2.json', 'data/gqa/questions/train_all_questions/train_all_questions_3.json', 'data/gqa/questions/train_all_questions/train_all_questions_4.json', 'data/gqa/questions/train_all_questions/train_all_questions_5.json', 'data/gqa/questions/train_all_questions/train_all_questions_6.json', 'data/gqa/questions/train_all_questions/train_all_questions_7.json', 'data/gqa/questions/train_all_questions/train_all_questions_8.json', 'data/gqa/questions/train_all_questions/train_all_questions_9.json']\n",
      "data/gqa/questions/val_all_questions.json\n",
      "data/gqa/questions/testdev_all_questions.json\n",
      "data/gqa/questions/test_all_questions.json\n",
      "data/gqa/questions/challenge_all_questions.json\n"
     ]
    }
   ],
   "source": [
    "# Extract image ids\n",
    "tiers = [split.value for split in GQASplit]\n",
    "\n",
    "for tier in tiers:\n",
    "    question_path = f\"data/gqa/questions/{tier}_all_questions.json\"\n",
    "    id_extractor = ImageIDExtractor()\n",
    "    load_and_apply_to_file(question_path, id_extractor)\n",
    "    with open(f\"temp/{tier}_ids.json\", \"w\") as f:\n",
    "        json.dump(id_extractor.ids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train: 74256\nval: 10564\ntestdev: 398\ntest: 2993\nchallenge: 1590\n"
     ]
    }
   ],
   "source": [
    "# Verify length of ids\n",
    "tiers = [split.value for split in GQASplit]\n",
    "for tier in tiers:\n",
    "    with open(f\"temp/{tier}_ids.json\", \"r\") as f:\n",
    "        print(f\"{tier}: {len(json.load(f))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get GQA vocab\n",
    "gqa_sg_root = Path(\"./artifacts/gqa-preprocessed:v11\")\n",
    "with open(gqa_sg_root / \"preprocessors.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    gt_sg_attr_vocab = data[\"scene_graphs\"][\"attr_to_index\"]\n",
    "    gt_sg_obj_vocab = data[\"scene_graphs\"][\"object_to_index\"]\n",
    "    gt_sg_rel_vocab = data[\"scene_graphs\"][\"rel_to_index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "oov_offset=2630\n",
      "data/gqa/inference/0\n",
      "{'board': 2630, 'engine': 2631, 'handle': 2632, 'jean': 2633, 'kid': 2634, 'light': 2635, 'pant': 2636, 'plane': 2637, 'railing': 2638, 'short': 2639, 'sneaker': 2640, 'stand': 2641, 'tile': 2642, 'track': 2643, 'wave': 2644}\n",
      "{'across': 2645, 'against': 2646, 'along': 2647, 'and': 2648, 'belonging to': 2649, 'for': 2650, 'from': 2651, 'has': 2652, 'laying on': 2653, 'made of': 2654, 'on back of': 2655, 'over': 2656, 'part of': 2657, 'says': 2658, 'to': 2659, 'wears': 2660}\n",
      "data/gqa/inference/1\n",
      "data/gqa/inference/10\n",
      "data/gqa/inference/11\n",
      "data/gqa/inference/12\n",
      "data/gqa/inference/13\n",
      "data/gqa/inference/14\n",
      "data/gqa/inference/2\n",
      "data/gqa/inference/3\n",
      "data/gqa/inference/4\n",
      "data/gqa/inference/5\n",
      "data/gqa/inference/6\n",
      "data/gqa/inference/7\n",
      "data/gqa/inference/8\n",
      "data/gqa/inference/9\n",
      "Saving preprocessors:\n",
      "Saving tier: train\n",
      "Saving tier: val\n",
      "Saving tier: testdev\n",
      "Saving tier: test\n",
      "Saving tier: challenge\n",
      "skipped=59053\n"
     ]
    }
   ],
   "source": [
    "# Load image ids\n",
    "tiers = [split.value for split in GQASplit]\n",
    "sgs = {tier: {} for tier in tiers}\n",
    "id_to_tier = {}\n",
    "for tier in tiers:\n",
    "    with open(f\"temp/{tier}_ids.json\", \"r\") as f:\n",
    "        tier_ids = json.load(f)\n",
    "        id_to_tier.update({i: tier for i in tier_ids})\n",
    "\n",
    "skipped = 0\n",
    "\n",
    "obj_vocab = None\n",
    "rel_vocab = None\n",
    "\n",
    "oov_obj_idxs = None\n",
    "oov_rel_idxs = None\n",
    "oov_offset = len(gt_sg_obj_vocab) + len(gt_sg_attr_vocab) + len(gt_sg_rel_vocab)\n",
    "print(f\"{oov_offset=}\")\n",
    "\n",
    "inference_root = Path(\"./data/gqa/inference\")\n",
    "for child in inference_root.iterdir():\n",
    "    if child.is_dir():\n",
    "        print(child)\n",
    "        with open(child / \"custom_data_info.json\", \"r\") as f:\n",
    "            meta = json.load(f)\n",
    "        idx_to_img_id = [Path(p).stem for p in meta[\"idx_to_files\"]]\n",
    "        if obj_vocab is None and rel_vocab is None:\n",
    "            \n",
    "            obj_vocab = meta[\"ind_to_classes\"]\n",
    "            rel_vocab = meta[\"ind_to_predicates\"]\n",
    "            oov_obj_idxs = [obj for obj in obj_vocab if obj not in gt_sg_obj_vocab.keys() and obj != \"__background__\"]\n",
    "            oov_rel_idxs = [rel for rel in rel_vocab if rel not in gt_sg_rel_vocab.keys() and rel != \"__background__\"]\n",
    "            oov_obj_idxs = {v: i + oov_offset for i, v in enumerate(oov_obj_idxs)}\n",
    "            oov_rel_idxs = {v: i + oov_offset + len(oov_obj_idxs) for i, v in enumerate(oov_rel_idxs)}\n",
    "            print(oov_obj_idxs)\n",
    "            print(oov_rel_idxs)\n",
    "\n",
    "        # Assert vocab doesnt change between children directories\n",
    "        assert obj_vocab == meta[\"ind_to_classes\"]\n",
    "        assert rel_vocab == meta[\"ind_to_predicates\"]\n",
    "\n",
    "        for i, img_id in enumerate(idx_to_img_id):\n",
    "            with open(child / \"inference\" / f\"custom_prediction_{i}.json\", \"r\") as f:\n",
    "                sg = json.load(f)[str(i)]\n",
    "                # Ensure there are no __background__ tags (verified and commented out for efficiency)\n",
    "                # assert 0 not in sg[\"bbox_labels\"] and 0 not in sg[\"rel_labels\"]\n",
    "\n",
    "                # Keys: bbox, bbox_labels, bbox_scores, rel_pairs, rel_labels, rel_scores\n",
    "                tier = id_to_tier.get(img_id)\n",
    "                if tier is None:\n",
    "                    # print(f\"skipping image: {img_id}\")\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "                if img_id in sgs[tier].keys():\n",
    "                    print(f\"Duplicate image id: {img_id}\")\n",
    "                sgs[tier][img_id] = {\n",
    "                    \"imageId\": img_id,\n",
    "                    \"boxes\": sg[\"bbox\"],\n",
    "                    \"box_scores\": sg[\"bbox_scores\"],\n",
    "                    \"labels\": [obj_vocab[i] for i in sg[\"bbox_labels\"]],\n",
    "                    \"attributes\": [],\n",
    "                    \"relations\": [rel_vocab[i] for i in sg[\"rel_labels\"]],\n",
    "                    \"relation_scores\": sg[\"rel_scores\"],\n",
    "                    \"coos\": [list(tup) for tup in zip(*sg[\"rel_pairs\"])]\n",
    "                }\n",
    "                # Determine OOV objects and relations\n",
    "                sgs[tier][img_id].update({\n",
    "                    \"indexed_labels\": [gt_sg_obj_vocab[lbl] if lbl in gt_sg_obj_vocab.keys() else oov_obj_idxs[lbl] for lbl in sgs[tier][img_id][\"labels\"]],\n",
    "                    \"indexed_attributes\": [],\n",
    "                    \"indexed_relations\": [gt_sg_rel_vocab[lbl] if lbl in gt_sg_rel_vocab.keys() else oov_rel_idxs[lbl] for lbl in sgs[tier][img_id][\"relations\"]]\n",
    "                })\n",
    "\n",
    "with open(gqa_sg_root / \"preprocessors.json\", \"r\") as f:\n",
    "    preprocessor_data = json.load(f)\n",
    "\n",
    "preprocessor_data[\"scene_graphs\"][\"oov_attr_to_index\"] = {}\n",
    "preprocessor_data[\"scene_graphs\"][\"oov_object_to_index\"] = oov_obj_idxs\n",
    "preprocessor_data[\"scene_graphs\"][\"oov_rel_to_index\"] = oov_rel_idxs\n",
    "\n",
    "print(f\"Saving preprocessors:\")\n",
    "with open(f\"temp/preprocessors.json\", \"w\") as f:\n",
    "    json.dump(preprocessor_data, f)\n",
    "\n",
    "for tier in tiers:\n",
    "    print(f\"Saving tier: {tier}\")\n",
    "    with open(f\"temp/{tier}_sceneGraphs.json\", \"w\") as f:\n",
    "        json.dump(sgs[tier], f)\n",
    "\n",
    "print(f\"{skipped=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['13: board', '42: engine', '59: handle', '67: jean', '68: kid', '76: light', '87: pant', '95: plane', '103: railing', '113: short', '120: sneaker', '123: stand', '129: tile', '134: track', '143: wave']\n['2: across', '3: against', '4: along', '5: and', '9: belonging to', '16: for', '17: from', '20: has', '24: laying on', '27: made of', '32: on back of', '33: over', '36: part of', '39: says', '42: to', '49: wears']\n"
     ]
    }
   ],
   "source": [
    "# Check vocab overlap with GQA\n",
    "\n",
    "print([f\"{obj_vocab.index(val)}: {val}\" for val in oov_obj_idxs])\n",
    "print([f\"{rel_vocab.index(val)}: {val}\" for val in oov_rel_idxs])\n",
    "\n",
    "\n",
    "# obj_class_remap = {obj: obj for obj in all_obj_vocab if obj in gt_sg_obj_vocab.keys()}\n",
    "# rel_class_remap = {rel: rel for rel in all_rel_vocab if rel not in gt_sg_rel_vocab.keys()}\n",
    "\n",
    "# obj_class_remap.update({\n",
    "#     \"stand\": \"nightstand\",  # Not ideal, as there are \"fruit stands\", etc.\n",
    "#     \"kid\": \"child\",\n",
    "#     \"plane\": \"airplane\",\n",
    "#     \"light\": \"lamp\",\n",
    "#     \"short\": \"shorts\",\n",
    "#     \"pant\": \"pants\",\n",
    "#     \"sneaker\": \"sneakers\",\n",
    "#     \"jean\": \"jeans\",\n",
    "#     \"__background__\": None\n",
    "# })\n",
    "\n",
    "\n",
    "# from torchtext.vocab import GloVe\n",
    "# import torch\n",
    "\n",
    "# embeddings = GloVe(dim=300, name=\"6B\")\n",
    "# oov_obj_embs = embeddings.get_vecs_by_tokens(oov_objs)\n",
    "# gqa_gt_obj_embs = embeddings.get_vecs_by_tokens(list(gt_sg_obj_vocab.keys()))\n",
    "# print(oov_obj_embs.size())\n",
    "# print(gqa_gt_obj_embs.size())\n",
    "# sim = torch.nn.CosineSimilarity()\n",
    "# sim = sim(oov_obj_embs.unsqueeze(-1), gqa_gt_obj_embs.t().unsqueeze(0))\n",
    "# vals, idxs = torch.max(sim, dim=1)\n",
    "# idxs = idxs.tolist()\n",
    "# gt_obj_idx_to_key = {v: k for k, v in gt_sg_obj_vocab.items()}\n",
    "# print([gt_obj_idx_to_key[i] for i in idxs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}